{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bbKbx185zqlz",
        "P8aNBqn9JviD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AK391/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Colab From https://github.com/TheLastBen/fast-stable-diffusion, if you have any issues, feel free to discuss them.** \n",
        "Run this Notebook manually step by step, don't miss any, the colab is still in progress, trying to find the best settings for Dreambooth\n"
      ],
      "metadata": {
        "id": "18MhcgMRmUlb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4Bae3VP6UsE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the environment"
      ],
      "metadata": {
        "id": "bbKbx185zqlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Install diffusers\n",
        "%%capture\n",
        "%cd /content/\n",
        "!git clone https://github.com/TheLastBen/diffusers\n",
        "!pip install git+https://github.com/TheLastBen/diffusers\n",
        "%pip install transformers\n",
        "%pip install ftfy\n",
        "%pip install accelerate\n",
        "%pip install bitsandbytes"
      ],
      "metadata": {
        "id": "QyvcqeiL65Tj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#xformers install for T4, P100 and V100"
      ],
      "metadata": {
        "id": "P8aNBqn9JviD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Cloning repo\n",
        "%%capture\n",
        "%cd /content/\n",
        "!git clone --branch gh/danthe3rd/35/orig https://github.com/facebookresearch/xformers.git"
      ],
      "metadata": {
        "id": "1pld5ps87a1q",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Patching setup.py\n",
        "%%writefile /content/xformers/setup.py\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "# Copyright (c) Facebook, Inc. and its affiliates. All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the BSD license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "\n",
        "import distutils.command.clean\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import setuptools\n",
        "import torch\n",
        "from torch.utils.cpp_extension import (\n",
        "    CUDA_HOME,\n",
        "    BuildExtension,\n",
        "    CppExtension,\n",
        "    CUDAExtension,\n",
        ")\n",
        "\n",
        "this_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "\n",
        "\n",
        "def fetch_requirements():\n",
        "    with open(\"requirements.txt\") as f:\n",
        "        reqs = f.read().strip().split(\"\\n\")\n",
        "    return reqs\n",
        "\n",
        "\n",
        "# https://packaging.python.org/guides/single-sourcing-package-version/\n",
        "def find_version(version_file_path):\n",
        "    with open(version_file_path) as version_file:\n",
        "        version_match = re.search(\n",
        "            r\"^__version__ = ['\\\"]([^'\\\"]*)['\\\"]\", version_file.read(), re.M\n",
        "        )\n",
        "        # The following is used to build release packages.\n",
        "        # Users should never use it.\n",
        "        suffix = os.getenv(\"XFORMERS_VERSION_SUFFIX\", \"\")\n",
        "        if version_match:\n",
        "            return version_match.group(1) + suffix\n",
        "        raise RuntimeError(\"Unable to find version string.\")\n",
        "\n",
        "\n",
        "def get_cuda_version(cuda_dir) -> int:\n",
        "    nvcc_bin = \"nvcc\" if cuda_dir is None else cuda_dir + \"/bin/nvcc\"\n",
        "    raw_output = subprocess.check_output([nvcc_bin, \"-V\"], universal_newlines=True)\n",
        "    output = raw_output.split()\n",
        "    release_idx = output.index(\"release\") + 1\n",
        "    release = output[release_idx].split(\".\")\n",
        "    bare_metal_major = int(release[0])\n",
        "    bare_metal_minor = int(release[1][0])\n",
        "\n",
        "    assert bare_metal_minor < 100\n",
        "    return bare_metal_major * 100 + bare_metal_minor\n",
        "\n",
        "\n",
        "def get_flash_attention_extensions(cuda_version: int, extra_compile_args):\n",
        "    # Figure out default archs to target\n",
        "    DEFAULT_ARCHS_LIST = \"\"\n",
        "    if cuda_version > 1100:\n",
        "        DEFAULT_ARCHS_LIST = \"7.5;8.0;8.6\"\n",
        "    elif cuda_version == 1100:\n",
        "        DEFAULT_ARCHS_LIST = \"7.5;8.0\"\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "    if os.getenv(\"XFORMERS_DISABLE_FLASH_ATTN\", \"0\") != \"0\":\n",
        "        return []\n",
        "\n",
        "    archs_list = os.environ.get(\"TORCH_CUDA_ARCH_LIST\", DEFAULT_ARCHS_LIST)\n",
        "    nvcc_archs_flags = []\n",
        "    for arch in archs_list.split(\";\"):\n",
        "        assert len(arch) >= 3, f\"Invalid sm version: {arch}\"\n",
        "\n",
        "        num = 10 * int(arch[0]) + int(arch[2])\n",
        "        # Need at least 7.5\n",
        "        if num < 75:\n",
        "            continue\n",
        "        nvcc_archs_flags.append(f\"-gencode=arch=compute_{num},code=sm_{num}\")\n",
        "        if arch.endswith(\"+PTX\"):\n",
        "            nvcc_archs_flags.append(f\"-gencode=arch=compute_{num},code=compute_{num}\")\n",
        "    if not nvcc_archs_flags:\n",
        "        return []\n",
        "\n",
        "    this_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "    flash_root = os.path.join(this_dir, \"third_party\", \"flash-attention\")\n",
        "    if not os.path.exists(flash_root):\n",
        "        raise RuntimeError(\n",
        "            \"flashattention submodule not found. Did you forget \"\n",
        "            \"to run `git submodule update --init --recursive` ?\"\n",
        "        )\n",
        "\n",
        "    return [\n",
        "        CUDAExtension(\n",
        "            name=\"xformers._C_flashattention\",\n",
        "            sources=[\n",
        "                os.path.join(this_dir, \"third_party\", \"flash-attention\", path)\n",
        "                for path in [\n",
        "                    \"csrc/flash_attn/fmha_api.cpp\",\n",
        "                    \"csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu\",\n",
        "                    \"csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu\",\n",
        "                    \"csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu\",\n",
        "                    \"csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu\",\n",
        "                ]\n",
        "            ],\n",
        "            extra_compile_args={\n",
        "                **extra_compile_args,\n",
        "                \"nvcc\": extra_compile_args.get(\"nvcc\", [])\n",
        "                + [\n",
        "                    \"-O3\",\n",
        "                    \"-U__CUDA_NO_HALF_OPERATORS__\",\n",
        "                    \"-U__CUDA_NO_HALF_CONVERSIONS__\",\n",
        "                    \"--expt-relaxed-constexpr\",\n",
        "                    \"--expt-extended-lambda\",\n",
        "                    \"--use_fast_math\",\n",
        "                    \"--ptxas-options=-v\",\n",
        "                    \"-lineinfo\",\n",
        "                ]\n",
        "                + nvcc_archs_flags,\n",
        "            },\n",
        "            include_dirs=[\n",
        "                Path(flash_root) / \"csrc\" / \"flash_attn\",\n",
        "                Path(flash_root) / \"csrc\" / \"flash_attn\" / \"src\",\n",
        "                #            Path(flash_root) / 'csrc' / 'flash_attn' / 'cutlass' / 'include',\n",
        "                Path(this_dir) / \"third_party\" / \"cutlass\" / \"include\",\n",
        "            ],\n",
        "        )\n",
        "    ]\n",
        "\n",
        "\n",
        "def get_extensions():\n",
        "    this_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "    extensions_dir = os.path.join(\n",
        "        this_dir, \"xformers\", \"components\", \"attention\", \"csrc\"\n",
        "    )\n",
        "\n",
        "    main_file = glob.glob(os.path.join(extensions_dir, \"*.cpp\"))\n",
        "\n",
        "    source_cpu = glob.glob(os.path.join(extensions_dir, \"cpu\", \"*.cpp\")) + glob.glob(\n",
        "        os.path.join(extensions_dir, \"autograd\", \"*.cpp\")\n",
        "    )\n",
        "\n",
        "    sources = main_file + source_cpu\n",
        "\n",
        "    source_cuda = glob.glob(\n",
        "        os.path.join(extensions_dir, \"cuda\", \"**\", \"*.cu\"), recursive=True\n",
        "    )\n",
        "\n",
        "    sputnik_dir = os.path.join(this_dir, \"third_party\", \"sputnik\")\n",
        "    cutlass_dir = os.path.join(this_dir, \"third_party\", \"cutlass\", \"include\")\n",
        "    if not os.path.exists(cutlass_dir):\n",
        "        raise RuntimeError(\n",
        "            \"CUTLASS submodule not found. Did you forget \"\n",
        "            \"to run `git submodule update --init --recursive` ?\"\n",
        "        )\n",
        "\n",
        "    extension = CppExtension\n",
        "\n",
        "    define_macros = []\n",
        "\n",
        "    extra_compile_args = {\"cxx\": [\"-O3\"]}\n",
        "    if sys.platform == \"win32\":\n",
        "        define_macros += [(\"xformers_EXPORTS\", None)]\n",
        "        extra_compile_args[\"cxx\"].append(\"/MP\")\n",
        "    elif \"OpenMP not found\" not in torch.__config__.parallel_info():\n",
        "        extra_compile_args[\"cxx\"].append(\"-fopenmp\")\n",
        "\n",
        "    include_dirs = [extensions_dir]\n",
        "    ext_modules = []\n",
        "\n",
        "    if (torch.cuda.is_available() and ((CUDA_HOME is not None))) or os.getenv(\n",
        "        \"FORCE_CUDA\", \"0\"\n",
        "    ) == \"1\":\n",
        "        extension = CUDAExtension\n",
        "        sources += source_cuda\n",
        "        include_dirs += [sputnik_dir, cutlass_dir]\n",
        "        nvcc_flags = os.getenv(\"NVCC_FLAGS\", \"\")\n",
        "        if nvcc_flags == \"\":\n",
        "            nvcc_flags = [\"--use_fast_math\", \"-DNDEBUG\"]\n",
        "        else:\n",
        "            nvcc_flags = nvcc_flags.split(\" \")\n",
        "        cuda_version = get_cuda_version(CUDA_HOME)\n",
        "        if cuda_version >= 1102:\n",
        "            nvcc_flags += [\n",
        "                \"--threads\",\n",
        "                \"4\",\n",
        "                \"--ptxas-options=-v\",\n",
        "            ]\n",
        "        extra_compile_args[\"nvcc\"] = nvcc_flags\n",
        "\n",
        "        ext_modules += get_flash_attention_extensions(\n",
        "            cuda_version=cuda_version, extra_compile_args=extra_compile_args\n",
        "        )\n",
        "\n",
        "    sources = [os.path.join(extensions_dir, s) for s in sources]\n",
        "\n",
        "    ext_modules.append(\n",
        "        extension(\n",
        "            \"xformers._C\",\n",
        "            sorted(sources),\n",
        "            include_dirs=include_dirs,\n",
        "            define_macros=define_macros,\n",
        "            extra_compile_args=extra_compile_args,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return ext_modules\n",
        "\n",
        "\n",
        "class clean(distutils.command.clean.clean):  # type: ignore\n",
        "    def run(self):\n",
        "        if os.path.exists(\".gitignore\"):\n",
        "            with open(\".gitignore\", \"r\") as f:\n",
        "                ignores = f.read()\n",
        "                for wildcard in filter(None, ignores.split(\"\\n\")):\n",
        "                    for filename in glob.glob(wildcard):\n",
        "                        try:\n",
        "                            os.remove(filename)\n",
        "                        except OSError:\n",
        "                            shutil.rmtree(filename, ignore_errors=True)\n",
        "\n",
        "        # It's an old-style class in Python 2.7...\n",
        "        distutils.command.clean.clean.run(self)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    setuptools.setup(\n",
        "        name=\"xformers\",\n",
        "        description=\"XFormers: A collection of composable Transformer building blocks.\",\n",
        "        version=find_version(os.path.join(this_dir, \"xformers\", \"__init__.py\")),\n",
        "        setup_requires=[],\n",
        "        install_requires=fetch_requirements(),\n",
        "        packages=setuptools.find_packages(exclude=(\"tests\", \"tests.*\")),\n",
        "\n",
        "        url=\"https://facebookresearch.github.io/xformers/\",\n",
        "        python_requires=\">=3.6\",\n",
        "        author=\"Facebook AI Research\",\n",
        "        author_email=\"lefaudeux@fb.com\",\n",
        "        long_description=\"XFormers: A collection of composable Transformer building blocks.\"\n",
        "        + \"XFormers aims at being able to reproduce most architectures in the Transformer-family SOTA,\"\n",
        "        + \"defined as compatible and combined building blocks as opposed to monolithic models\",\n",
        "        long_description_content_type=\"text/markdown\",\n",
        "        classifiers=[\n",
        "            \"Programming Language :: Python :: 3.7\",\n",
        "            \"Programming Language :: Python :: 3.8\",\n",
        "            \"Programming Language :: Python :: 3.9\",\n",
        "            \"License :: OSI Approved :: BSD License\",\n",
        "            \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n",
        "            \"Operating System :: OS Independent\",\n",
        "        ],\n",
        "        zip_safe=False,\n",
        "    )\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "snsgXQXv9UlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Installing\n",
        "%%capture\n",
        "!pip install /content/xformers\n",
        "!pip install triton==2.0.0.dev20220701"
      ],
      "metadata": {
        "id": "pUR6RB8Z72NB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Precompiled files\n",
        "%%capture\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %cd /content/\n",
        "  !git clone https://github.com/TheLastBen/fast-stable-diffusion\n",
        "  %cd /content/fast-stable-diffusion/precompiled\n",
        "  !mv /content/fast-stable-diffusion/precompiled/_C_flashattention.1 /content/fast-stable-diffusion/precompiled/_C_flashattention.7z.001\n",
        "  !mv /content/fast-stable-diffusion/precompiled/_C_flashattention.2 /content/fast-stable-diffusion/precompiled/_C_flashattention.7z.002\n",
        "  !7z x /content/fast-stable-diffusion/precompiled/_C_flashattention.7z.001\n",
        "  !mv -f /content/fast-stable-diffusion/precompiled/_C_flashattention.so /usr/local/lib/python3.7/dist-packages/xformers\n",
        "  !mv -f /content/fast-stable-diffusion/precompiled/_C.so /usr/local/lib/python3.7/dist-packages/xformers\n",
        "\n",
        "elif (gpu=='P100'):\n",
        "  %cd /content/\n",
        "  !git clone https://github.com/TheLastBen/fast-stable-diffusion\n",
        "  %cd /content/fast-stable-diffusion/precompiled\n",
        "  !mv /content/fast-stable-diffusion/precompiled/_C_flashattention-p100.1 /content/fast-stable-diffusion/precompiled/_C_flashattention.7z.001\n",
        "  !mv /content/fast-stable-diffusion/precompiled/_C_flashattention-p100.2 /content/fast-stable-diffusion/precompiled/_C_flashattention.7z.002\n",
        "  !7z x /content/fast-stable-diffusion/precompiled/_C_flashattention.7z.001\n",
        "  !mv -f /content/fast-stable-diffusion/precompiled/_C.flashattention.so /usr/local/lib/python3.7/dist-packages/xformers/_C_flashattention.so\n",
        "  !mv -f /content/fast-stable-diffusion/precompiled/_C-p100.so /usr/local/lib/python3.7/dist-packages/xformers/_C.so\n",
        "  \n",
        "elif (gpu=='V100'):\n",
        "  %cd /content/\n",
        "  !git clone https://github.com/TheLastBen/fast-stable-diffusion\n",
        "  %cd /content/fast-stable-diffusion/precompiled\n",
        "  !mv /content/fast-stable-diffusion/precompiled/_C_flashattention-v100.1 /content/fast-stable-diffusion/precompiled/_C_flashattention.7z.001\n",
        "  !mv /content/fast-stable-diffusion/precompiled/_C_flashattention-v100.2 /content/fast-stable-diffusion/precompiled/_C_flashattention.7z.002\n",
        "  !7z x /content/fast-stable-diffusion/precompiled/_C_flashattention.7z.001\n",
        "  !mv -f /content/fast-stable-diffusion/precompiled/_C_flashattention.so /usr/local/lib/python3.7/dist-packages/xformers/\n",
        "  !mv -f /content/fast-stable-diffusion/precompiled/_C-v100.so /usr/local/lib/python3.7/dist-packages/xformers/_C.so\n",
        "  "
      ],
      "metadata": {
        "id": "t19UXalj9gA5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caching the model in GDrive"
      ],
      "metadata": {
        "id": "R3SsbIlxw66N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Downloading the model\n",
        "%%capture\n",
        "import os\n",
        "Huggingface_Token = \"\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown (Make sure you accepted the terms in https://huggingface.co/CompVis/stable-diffusion-v1-4)\n",
        "token=Huggingface_Token\n",
        "if token == \"\" and not os.path.exists('/content/gdrive/MyDrive/stable-diffusion-v1-4'):\n",
        "  token=input(\"Insert your huggingface token :\")\n",
        "  %cd /content/\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git clone \"https://USER:{token}@huggingface.co/CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "elif not os.path.exists('/content/gdrive/MyDrive/stable-diffusion-v1-4'):\n",
        "  %cd /content/\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git clone \"https://USER:{token}@huggingface.co/CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "else:\n",
        "  print(\"Model already exists\")\n",
        "\n",
        "!rsync -av --progress /content/stable-diffusion-v1-4 /content/gdrive/MyDrive --exclude .git\n",
        "!rm -r /content/stable-diffusion-v1-4\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "O3KHGKqyeJp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dreambooth"
      ],
      "metadata": {
        "id": "0tN76Cj5P3RL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "#@markdown #Setting up\n",
        "#@markdown ---\n",
        "MODEL_NAME=\"/content/gdrive/MyDrive/stable-diffusion-v1-4\"\n",
        "#@markdown ### Training subject (is it a person ? a dog ? a car ? pick the correct category):\n",
        "SUBJECT_NAME= \"\" #@param{type: 'string'}\n",
        "#@markdown ### Identifier (choose a unique identifier unknown by stable diffusion ):\n",
        "INSTANCE_NAME= \"\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown ### This cell will ask you to upload your reference images, for best result, make sure they are square, eg: 1024x1024\n",
        "INSTANCE_DIR=\"/content/data/\"+INSTANCE_NAME\n",
        "!mkdir -p $INSTANCE_DIR\n",
        "CLASS_DIR=\"/content/data/\"+ SUBJECT_NAME\n",
        "OUTPUT_DIR=\"/content/models/\"+ INSTANCE_NAME\n",
        "# upload images\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  shutil.move(filename, INSTANCE_DIR)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1pH1oP-7yBZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown #Start DreamBooth\n",
        "#@markdown ---\n",
        "Training_Steps=800 #@param{type: 'string'}\n",
        "Seed=\"12345\" #@param{type: 'string'}\n",
        "#@markdown ####More steps, better results, but longer training time\n",
        "!accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --instance_data_dir=$INSTANCE_DIR \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --instance_prompt=\"photo of {INSTANCE_NAME} {SUBJECT_NAME}\"\\\n",
        "  --seed=$Seed \\\n",
        "  --resolution=512 \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --use_8bit_adam \\\n",
        "  --learning_rate=5e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=$Training_Steps"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1-9QbkfAVYYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Save the new model in your Gdrive (make sure there is enough space)\n",
        "!cp -r \"/content/models/\" /content/gdrive/MyDrive"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5HUiPJjqMxDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model"
      ],
      "metadata": {
        "id": "_ZJ2wlbkWAIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Load the new Model\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from IPython.display import display\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained('/content/gdrive/MyDrive/models/'+INSTANCE_NAME, torch_dtype=torch.float16).to(\"cuda\")\n",
        "def dummy(images, **kwargs):\n",
        "    return images, False\n",
        "pipe.safety_checker = dummy"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TjCKxXsDQJ3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Stable Diffusion\n",
        "\n",
        "#@markdown #####Run the Stable Diffusion pipeline with interactive UI Demo on Gradio\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def inference(prompt,Height,Width,Steps,Scale, num_samples):\n",
        "    all_images = [] \n",
        "    with torch.autocast(\"cuda\"):\n",
        "            images = pipe([prompt] * num_samples, height=Height, width=Width, num_inference_steps=Steps, guidance_scale=Scale).images\n",
        "            all_images.extend(images)\n",
        "    return all_images\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"prompt\")\n",
        "            Height = gr.Slider(label=\"Height\",value=512)\n",
        "            Width = gr.Slider(label=\"Width\",value=512)\n",
        "            Steps = gr.Slider(label=\"Steps\",value=50)\n",
        "            samples = gr.Slider(label=\"Samples\",value=1)\n",
        "            Scale = gr.Slider(label=\"Scale\",value=8)\n",
        "            run = gr.Button(value=\"Run\")\n",
        "        with gr.Column():\n",
        "            gallery = gr.Gallery(show_label=False)\n",
        "\n",
        "    run.click(inference, inputs=[prompt,Height,Width,Steps,Scale, samples], outputs=gallery)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "hMi69nB1ThGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kA1wT9EwVtPZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}